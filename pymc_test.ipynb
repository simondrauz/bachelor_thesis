{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## I. Prerequesites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Import Packages**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytensor.tensor as at\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Define functions**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize a pandas DataFrame\"\"\"\n",
    "    standardized_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        standardized_column = (df[column] - df[column].mean()) / df[column].std()\n",
    "        standardized_df[column] = standardized_column\n",
    "    return standardized_df\n",
    "\n",
    "def standardize_series(series):\n",
    "    \"\"\"Standardize a pandas series\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def take_logarithm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"take logarithm a pandas DataFrame\"\"\"\n",
    "    logarithmized_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        logarithmized_column = np.log(df[column])\n",
    "        logarithmized_df[column] = logarithmized_column\n",
    "    return logarithmized_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Set style and generate random seed**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-darkgrid\")\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " **1. Load data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pd.read_parquet(r'C:\\Users\\Uwe Drauz\\Documents\\bachelor_thesis_local\\personal_competition_data\\temp\\X.parquet')\n",
    "y = pd.read_parquet(r'C:\\Users\\Uwe Drauz\\Documents\\bachelor_thesis_local\\personal_competition_data\\temp\\y.parquet')\n",
    "X = X.reset_index(drop=True, inplace=False)\n",
    "y = y.reset_index(drop=True, inplace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Standardize data and/or take loagrithm of data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standardize target variable y\n",
    "y_std = standardize(y)\n",
    "\n",
    "# Calculate the standardized logarithm of input data X\n",
    "X_std= standardize(X)\n",
    "X_std_log = take_logarithm(X_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Create data frames with standardized and/or logarithmized data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create data frame with target variable and standardized input data\n",
    "df_Y_non_std_X_std = pd.concat([y, X_std], axis=1)\n",
    "# Create data frame with standardized target variable and standardized input data\n",
    "df_Y_std_X_Std = pd.concat([y_std, X_std], axis=1)\n",
    "# Create data frame with target variable and standardized logarithm of input data\n",
    "df_Y_non_std_X_std_log = pd.concat([y, X_std_log], axis=1)\n",
    "# Create data frame with standardized target variable and standardized logarithm of input data\n",
    "df_Y_std_X_std_log = pd.concat([y_std, X_std_log], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Define which data to use**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_Y_non_std_X_std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III. Model Building"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dictionary for implicit handling of data\n",
    "COORDS = {\"predictors\": ['ged_sb_tlag_1', 'ged_sb_tsum_24'], \"obs_idx\": df.index}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Build Bayesian model with Gaussian distribution**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pm.Model(coords=COORDS) as bayesian_model_gauss:\n",
    "    # Define the priors for regressors and standard deviation\n",
    "    intercept = pm.Normal('intercept', 0.0, 1.0)\n",
    "    beta = pm.Normal(\"slopes\", 0.0, 1.0, dims=\"predictors\")\n",
    "    sigma = pm.HalfNormal(\"sigma\", 25)\n",
    "\n",
    "    # Specify the data\n",
    "    X1 = pm.ConstantData(\"fatality lag t=1\", df.ged_sb_tlag_1.to_numpy(), dims=\"obs_idx\")\n",
    "    X2 = pm.ConstantData(\"fatality rolling average t=24\", df.ged_sb_tsum_24.to_numpy(), dims=\"obs_idx\")\n",
    "    Y = pm.ConstantData(\"fatility count\", df.ged_sb.to_numpy(), dims=\"obs_idx\")\n",
    "\n",
    "    # Specify mean of gaussian distribution\n",
    "    mu = intercept +  beta[0] * X1 + beta[1] * X2\n",
    "    # mean for target variable\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=Y, dims=\"obs_idx\")\n",
    "\n",
    "    # Run the sampling using the No-U-Turn Sampler (NUTS) for the specified number of samples\n",
    "    idata_bayesian_gauss = pm.sample(1000, tune=2000, random_seed=rng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with bayesian_model_gauss:\n",
    "    ppc_prior = pm.sample_prior_predictive(samples=500, random_seed=rng)\n",
    "    pm.sample_posterior_predictive(idata_bayesian_gauss, extend_inferencedata=True, random_seed=rng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Build Bayesian model with Negative Binomial distribution**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model\n",
    "with pm.Model(coords=COORDS) as bayesian_model_nb:\n",
    "    # Define the priors for regressors and  negative binomial over-dispersion parameter\n",
    "    intercept = pm.HalfNormal(\"intercept\", sigma=0.1)\n",
    "    beta = pm.Normal(\"slopes\", 0.0, 10, dims=\"predictors\")\n",
    "    alpha = pm.HalfNormal('alpha', 2.5)\n",
    "\n",
    "    # Specify the data\n",
    "    X1 = pm.ConstantData(\"fatality lag t=1\", df.ged_sb_tlag_1.to_numpy(), dims=\"obs_idx\")\n",
    "    X2 = pm.ConstantData(\"fatality rolling average t=24\", df.ged_sb_tsum_24.to_numpy(), dims=\"obs_idx\")\n",
    "    Y = pm.ConstantData(\"fatility count\", df.ged_sb.to_numpy(), dims=\"obs_idx\")\n",
    "\n",
    "    # Note: Possibly an option to change to pm.Deterministic\n",
    "    # Define mean of negative binomial distribution\n",
    "    mu = pm.math.exp(intercept + beta[0] * X1 + beta[1] * X2)\n",
    "\n",
    "    # Define the likelihood\n",
    "    obs = pm.NegativeBinomial(\"obs\", mu=mu, alpha=alpha, observed=Y, dims=\"obs_idx\")\n",
    "\n",
    "    # Note: Optionally define cores and chains\n",
    "    # Run the sampling using the No-U-Turn Sampler (NUTS) for the specified number of samples\n",
    "    idata_bayesian_nb = pm.sample(draws=1000, tune=2000, random_seed=rng, target_accept=0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with bayesian_model_nb:\n",
    "    ppc_prior = pm.sample_prior_predictive(samples=500, random_seed=rng)\n",
    "    ppc_posterior = pm.sample_posterior_predictive(idata_bayesian_nb, extend_inferencedata=True, random_seed=rng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV. Model Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T11:30:37.829982Z",
     "start_time": "2023-07-17T11:30:37.779118300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RangeIndex(start=0, stop=299, step=1)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "**tbd: what exactly do we examine here?**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Analysis for negative binomial model**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify which model should be examined\n",
    "model = bayesian_model_nb\n",
    "idata = idata_bayesian_nb\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_trace(idata)\n",
    "az.plot_trace(idata, combined=True)\n",
    "az.plot_posterior(idata)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform coefficients to recover parameter values\n",
    "az.summary(np.exp(idata.posterior), kind=\"stats\", var_names=[\"intercept\", \"slopes\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.summary(idata.posterior, kind=\"stats\", var_names=\"alpha\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_ppc(idata, num_pp_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Analysis for Gaussian model**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify which model should be examined\n",
    "model = bayesian_model_gauss\n",
    "idata = idata_bayesian_gauss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_trace(idata)\n",
    "az.plot_trace(idata, combined=True)\n",
    "az.plot_posterior(idata)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform coefficients to recover parameter values\n",
    "az.summary(np.exp(idata.posterior), kind=\"stats\", var_names=[\"intercept\", \"slopes\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.summary(idata.posterior, kind=\"stats\", var_names=\"sigma\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_ppc(idata, num_pp_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## V. Test functionalities with simulated data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "true_a, true_b, predictor = 0.5, 3.0, rng.normal(loc=2, scale=6, size=N)\n",
    "true_mu = true_a + true_b * predictor\n",
    "true_sd = 2.0\n",
    "\n",
    "outcome = rng.normal(loc=true_mu, scale=true_sd, size=N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor_scaled = standardize_series(predictor)\n",
    "outcome_scaled = standardize_series(outcome)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pm.Model() as model_1:\n",
    "    a = pm.Normal(\"a\", 0.0, 0.5)\n",
    "    b = pm.Normal(\"b\", 0.0, 1.0)\n",
    "\n",
    "    mu = a + b * predictor_scaled\n",
    "    sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "\n",
    "    pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=outcome_scaled)\n",
    "    idata = pm.sample_prior_predictive(samples=50, random_seed=rng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with model_1:\n",
    "    idata.extend(pm.sample(1000, tune=2000, random_seed=rng))\n",
    "\n",
    "az.plot_trace(idata);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with model_1:\n",
    "    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_ppc(idata, num_pp_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VI. Data exploration steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor_scaled.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outcome_scaled.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intercept"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "η"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha/(mu + alpha)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
